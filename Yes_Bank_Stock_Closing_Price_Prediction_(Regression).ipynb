{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "PBTbrJXOngz2",
        "7p2Z9afqlBXI",
        "bKJF3rekwFvQ",
        "c-aJGkH8lOm0",
        "z_-Gn0vvlaka",
        "MSa1f5Uengrz",
        "yLjJCtPM0KBk",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishan711997/ML_linear_model_for_Stock_Closing_Price/blob/main/Yes_Bank_Stock_Closing_Price_Prediction_(Regression).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Yes Bank Stock Closing Price Prediction"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Ishan Srivastava"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project aimed to analyze stock price data for Yes Bank and build predictive models using Linear Regression, Lasso Regression, and Ridge Regression. The dataset contained information about the stock's opening, closing, high, and low prices for various months and years. The primary objective was to predict the closing stock price based on the other variables.\n",
        "\n",
        "The initial data exploration revealed that the dataset had no missing values or null values. The date column was converted from an object type to a datetime datatype, and it was set as the index for time series analysis. The exploratory data analysis (EDA) was performed to gain insights into the stock's historical price trends.\n",
        "\n",
        "The EDA showed that the stock's all-time maximum closing price was around 370 units, while the minimum was approximately 10 units. There were fluctuations in the stock's high and low prices over time, and the relationship between these variables was linear. The opening and closing prices also exhibited a linear relationship. Furthermore, the distribution of features was right-skewed, and some potential outliers were present, but they were not removed from the dataset.\n",
        "\n",
        "To prepare the data for modeling, log transformations were applied to both the independent and dependent variables to improve their distribution. The dataset was then split into training and testing sets, and the data was standardized using StandardScaler.\n",
        "\n",
        "Three machine learning models were implemented and evaluated - Linear Regression, Lasso Regression, and Ridge Regression. Initially, the models were implemented without hyperparameter tuning. Linear Regression achieved impressive performance, with a high R-squared value of 0.99374, indicating a strong fit to the data. However, hyperparameter tuning using GridSearchCV significantly improved the performance of all models.\n",
        "\n",
        "After hyperparameter tuning, all three models exhibited exceptional performance. The tuned Lasso Regression had the lowest MAE of 0.0173, followed closely by Ridge Regression with an MAE of 0.01772. Linear Regression achieved an MAE of 0.017328. Similarly, the RMSE values were quite low, indicating accurate predictions.\n",
        "\n",
        "Finally, the evaluation metric scores were plotted to visualize the performance of the models. Although all three models performed well, Linear Regression with hyperparameter tuning had the highest adjusted R-squared, indicating the best fit for the data while considering the number of predictors. Therefore, Linear Regression was chosen as the final prediction model for this project.\n",
        "\n",
        "The model was saved in a joblib file for future deployment and prediction on unseen data. With this model, stakeholders can make informed decisions about stock investments and plan their financial strategies based on reliable predictions of Yes Bank's closing stock price.\n",
        "\n",
        "In conclusion, the project successfully analyzed historical stock price data for Yes Bank and developed robust predictive models using machine learning techniques. The chosen model, Linear Regression, exhibited the best performance and can be utilized for making accurate predictions on new data. The project demonstrates the effectiveness of machine learning in the financial domain and how it can help investors and financial analysts in making informed decisions."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/ishan711997/ML_linear_model_for_Stock_Closing_Price.git"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes Bank is a well-known bank in the Indian financial domain. Since 2018, it has been in the news because of the fraud case involving Rana Kapoor. Owing to this fact, it was interesting to see how that impacted the stock prices of the company and whether Time series models or any other predictive models can do justice to such situations. This dataset has monthly stock prices of the bank since its inception and includes closing, starting, highest, and lowest stock prices of every month. The main objective is to predict the stock's closing price of the month."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split    # for splitting the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# for setting x axis year range\n",
        "import matplotlib.dates as mdates"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cdRko8ZS35jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Capstone Projects/Capstone P2/data/data_YesBank_StockPrices.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "data.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # convert string object to datetime object\n",
        "# data['Date'] = data['Date'].apply(lambda x: datetime.strptime(x, \"%b-%y\"))"
      ],
      "metadata": {
        "id": "Zm5jjI18W8uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(data[data.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(data.isnull(), cbar=False, yticklabels=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to given Dataset there is\n",
        "\n",
        "\n",
        "*   no null values.\n",
        "*   date column is a object type and other columns are float.\n",
        "*   5 column and 185 rows\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "data.describe(include= 'all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  **Date**: It denotes the month and year of the for a particular price.\n",
        "*  **Open**: The opening price of the stock on that particular month.\n",
        "*  **High**: The highest price the stock reached during the month.\n",
        "*  **Low**: The lowest price the stock reached during the month.\n",
        "*  **Close**: The closing price of the stock on that particular month."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "data.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling and EDA***"
      ],
      "metadata": {
        "id": "7p2Z9afqlBXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Wrangling Code**"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making a copy of data and assign to df\n",
        "df = data.copy()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting date column, from object to datetime datatype\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y', errors = 'ignore')"
      ],
      "metadata": {
        "id": "TPqAi_hFvva5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all features related to date so we set date as a index\n",
        "df.set_index(keys='Date', inplace = True)"
      ],
      "metadata": {
        "id": "rXp7zBJv7Pgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['High', 'Low', 'Open']]  # Independent variables\n",
        "Y = df['Close']                  # Dependent variable"
      ],
      "metadata": {
        "id": "JJ5ct4ywDrsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **functions**"
      ],
      "metadata": {
        "id": "c-aJGkH8lOm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# made a functin for setting the frequency of x-axis ticks to show every year\n",
        "def x_year_lable():\n",
        "  years = mdates.YearLocator()\n",
        "  plt.gca().xaxis.set_major_locator(years)"
      ],
      "metadata": {
        "id": "e2-NvTlUNCS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function ---- 1\n",
        "# range detection function\n",
        "def range_detection(col1, col2, title):\n",
        "  high_low_range = df[col1] - df[col2]\n",
        "\n",
        "  plt.figure(figsize=(15,10))\n",
        "\n",
        "  # Plot the trading range over time\n",
        "  plt.plot(df.index, high_low_range)\n",
        "  plt.title(title)\n",
        "  plt.xlabel(\"Year\")\n",
        "  plt.ylabel(\"Trading Range\")\n",
        "\n",
        "  x_year_lable()"
      ],
      "metadata": {
        "id": "Z2lmLnQXOuuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function ---- 2\n",
        "# funtion for ploting variation of two columns over time\n",
        "def price_comparison(col1, col2, title):\n",
        "  plt.figure(figsize=(15,10))\n",
        "\n",
        "\n",
        "  sns.barplot(x=df.index.year, y=col1, data=df, color='blue', alpha=0.7, label=col1)\n",
        "  sns.barplot(x=df.index.year, y=col2, data=df, color='orange', alpha=0.7, label=col2)\n",
        "\n",
        "  plt.title(title)\n",
        "  plt.xlabel(\"Date\")\n",
        "  plt.ylabel(\"Price\")\n",
        "  plt.legend()\n"
      ],
      "metadata": {
        "id": "cZ2xPAKbWFDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function ---- 3\n",
        "# function for relation of two columns\n",
        "def relation_plot(col1, col2, title):\n",
        "  plt.scatter(df[col1], df[col2])\n",
        "  plt.title(title)\n",
        "  plt.xlabel(f\"{col1} Price\")\n",
        "  plt.ylabel(f\"{col2} Price\")"
      ],
      "metadata": {
        "id": "k-pegbOLBPAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function ---- 4\n",
        "# function for checking distribution and outlier\n",
        "def hist_box():\n",
        "  for column in df:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # for histogram\n",
        "    # plt.subplot(1, 2, 1)\n",
        "    sns.histplot(df[column], kde = True)"
      ],
      "metadata": {
        "id": "fx_rcMH_OJJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EDA**"
      ],
      "metadata": {
        "id": "z_-Gn0vvlaka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Maximum and Minimum price of stock for Open and Close price\n",
        "plt.bar(['Open', 'Close'], [df['Open'].max(), df['Close'].max()], label='Maximum')\n",
        "plt.bar(['Open', 'Close'], [df['Open'].min(), df['Close'].min()], label='Minimum')\n",
        "\n",
        "# Set the title and labels\n",
        "plt.title(\"Maximum and Minimum  for Open and Close Prices\")\n",
        "plt.xlabel(\"Price Type\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "OLBgcMRbyJAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. what is the difference between high and low price of the stock over time?\n",
        "range_detection('High','Low', title= 'Difference b/w High & Low Price Over Time')"
      ],
      "metadata": {
        "id": "IFfTPS5xTfow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. How does High price and Low price vary over time?\n",
        "price_comparison('High', 'Low', title = 'High Price vs Low Price Over Time')"
      ],
      "metadata": {
        "id": "wwzG5CD2F5TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. What is the relationship between the high price and low price of the stock?\n",
        "relation_plot('High', 'Low', title=\"High Price vs Low Price\")"
      ],
      "metadata": {
        "id": "xtTiDsN8Bmkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. What is the difference between the opening price and closing price of the stock over time?\n",
        "range_detection('Close', 'Open', title = 'Difference b/w Open & Close Price Over Time')"
      ],
      "metadata": {
        "id": "Wo2cEyyqVjLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. How does the opening price vary with the closing price over time\n",
        "price_comparison('Open', 'Close', title = 'Opening Price vs Closing Price Over Time')"
      ],
      "metadata": {
        "id": "wm3wDng9YJ2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. What is the relationship between the opening price and closing price of the stock?\n",
        "relation_plot('Open', 'Close', title=\"Opening Price vs Closing Price\")"
      ],
      "metadata": {
        "id": "nV9_ADAmC--k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create histogram and boxplot for all columns to identify how it is distributed\n",
        "hist_box()"
      ],
      "metadata": {
        "id": "_ieQBrnQPpVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ploting scatter plot independent features w.r.t. Closing price\n",
        "\n",
        "for col in X:\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.scatter(x=df[col], y=Y)\n",
        "  plt.xlabel(col)\n",
        "  plt.ylabel('Closing Price')"
      ],
      "metadata": {
        "id": "3rlexHAvPqfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap for all features\n",
        "sns.heatmap(df.corr(), annot = True,)"
      ],
      "metadata": {
        "id": "vXiFZtTLPwNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot\n",
        "sns.pairplot(df)"
      ],
      "metadata": {
        "id": "54r2tOeYPwSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*\tMade a copy of data and assigned to df.\n",
        "*\tConverted “Date” column from object type to datetime datatype. and set “Date” column to index.\n",
        "*\tDifferentiate independent and dependent variables.\n",
        "*\tMade some functions.\n",
        "*\tStock’s all time maximum of opening and closing price is approx. 370. Whereas all time minimum price is approx. 10\n",
        "*\tIn September of 2018 there was huge difference between stock’s high and low price that was more than 180. Means investors were withdrawing money.\n",
        "*\tSince 2016 to 2017 there was sharp jump in stock prices, and since 2018 stock prices continually falling down.\n",
        "*\tRelation b/w High and Low price is linear.\n",
        "*\tIn September of 2018 the closing price was approximately 160 units lower than the opening price.\n",
        "* In 2016-17 we can see opening price is lower than the closing price. Means during that specific time frame stock has gained value.\n",
        "* Relation b/w Open and Close price is linear.\n",
        "*\tAll features is right(+ve) skewed. And every feature have potential outlier. But I decided to not remove them.\n",
        "*\tAll independent features (high, low, open) linearly related to closing price.\n",
        "*\tEvery feature is highly co-related to each other (in scale 0.98 to 1), it is better for dependent var to be highly co-related to independent, but when independent vars highly co-related to each other, then it is called multicollinearity which is not good for models\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Null Values & Missing Value Imputation\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "there is no Null & Missing values"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating arrays of our input variable and label to feed the data to the model.\n",
        "# Create the data of independent variables\n",
        "X = np.log10(X).values            # applying log transform on our independent variables.\n",
        "\n",
        "# Create the dependent variable data\n",
        "Y = np.log10(Y).values               # applying log transform on our dependent variable."
      ],
      "metadata": {
        "id": "UqfP2OpvcbPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling the data.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "wGCS5NWldMmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing LinearRegression model and the metrics\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# cross validation and hyperparameter tuning libray\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "RC8jN5bxd6PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# empty dataframe for all metric tools performance\n",
        "per_df = pd.DataFrame()         # for before cross validation & hyperparameter\n",
        "tuned_per_df = pd.DataFrame()   # for after cross validation & hyperparameter"
      ],
      "metadata": {
        "id": "Sr3aO-Y2YrmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 **Linear Regression**"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "\n",
        "# fiting model line on our data\n",
        "lr.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "rElfM87IeEfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr.score(x_train, y_train)"
      ],
      "metadata": {
        "id": "H8Xjqp-_duGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, x_test.shape)"
      ],
      "metadata": {
        "id": "3xzsbHTabZb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on our test data\n",
        "y_pred = lr.predict(x_test)"
      ],
      "metadata": {
        "id": "6BqWOsEheScD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr.intercept_"
      ],
      "metadata": {
        "id": "Rjxgr9OpeSUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr.coef_"
      ],
      "metadata": {
        "id": "kcTrBcWleSB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performace of metrics**"
      ],
      "metadata": {
        "id": "617hzrV1fkMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = round(mean_absolute_error(10**(y_test), 10**(y_pred)),5)\n",
        "mse = round(mean_squared_error(10**(y_test), 10**(y_pred)),5)\n",
        "rmse = round(np.sqrt(mse),5)\n",
        "r2 = round(r2_score(10**(y_test), 10**(y_pred)),5)\n",
        "\n",
        "# Calculate the number of observations and the number of independent variables\n",
        "n = x_test.shape[0]\n",
        "k = x_test.shape[1]\n",
        "# Calculate the adjusted R-squared\n",
        "adjusted_r2 = round(1 - (1 - r2) * ((n - 1) / (n - k - 1)), 5)"
      ],
      "metadata": {
        "id": "S3jL09F1fHTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MAE (Linear) : {mae}\")\n",
        "print(f\"MSE (Linear): {mse}\")\n",
        "print(f\"RMSE (Linear): {rmse}\")\n",
        "print(f\"R-squared (Linear): {r2}\")\n",
        "print(f\"Adjusted R-squared (Linear): {adjusted_r2}\")"
      ],
      "metadata": {
        "id": "ZPCP6MitfHhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inserting performance of metric tools in per_df\n",
        "per_df.loc[0,'Model Name'] = 'Linear Regression'\n",
        "per_df.loc[0,'MAE'] = mae\n",
        "per_df.loc[0,'MSE'] = mse\n",
        "per_df.loc[0,'RMSE'] = rmse\n",
        "per_df.loc[0,'R2'] = r2\n",
        "per_df.loc[0,'ADJUSTED_R2'] = adjusted_r2"
      ],
      "metadata": {
        "id": "g6_mZZ_yZKWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,4))\n",
        "# Evaluation metric names\n",
        "metrics = [ 'MAE', 'MSE', 'RMSE','R-squared', 'Adjusted R-squared']\n",
        "\n",
        "# Evaluation metric values\n",
        "values = [mae, mse, rmse, r2, adjusted_r2]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.bar(metrics, values)"
      ],
      "metadata": {
        "id": "_XUlij5e79ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the actual and predicted test data.\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(10**y_pred)\n",
        "plt.plot(np.array(10**y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('Test Data')\n",
        "plt.ylabel(\"Price\")\n",
        "plt.title(\"Actual vs Predicted Closing price using Linear regression\")"
      ],
      "metadata": {
        "id": "Gwy-6WT9neOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the hyperparameter grid to search (empty for linear regression)\n",
        "parameters = {}\n",
        "\n",
        "# Fit the model using GridSearchCV for hyperparameter tuning and cross-validation\n",
        "linear_reg_regressor = GridSearchCV(lr, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "linear_reg_regressor.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = linear_reg_regressor.predict(x_test)\n",
        "\n",
        "# Calculate evaluation metric values after cross validation and hyperparameter tuning\n",
        "tuned_lr_mae = mean_absolute_error(y_test, y_pred)\n",
        "tuned_lr_mse = mean_squared_error(y_test, y_pred)\n",
        "tuned_lr_rmse = np.sqrt(tuned_lr_mse)\n",
        "tuned_lr_r2 = r2_score(y_test, y_pred)\n",
        "tuned_lr_adjusted_r2 = round(1 - (1 - r2) * ((n - 1) / (n - k - 1)), 5)\n"
      ],
      "metadata": {
        "id": "lQnUmajThJly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the evaluation metric values after cross validation and hyperparameter tuning\n",
        "print(\"Mean Absolute Error(Linear):\", tuned_lr_mae)\n",
        "print(\"Mean Squared Error(Linear):\", tuned_lr_mse)\n",
        "print(\"Root Mean Squared Error(Linear):\", tuned_lr_rmse)\n",
        "print(\"R-squared(Linear):\", tuned_lr_r2)\n",
        "print(\"Adjusted R-squared(Linear):\", tuned_lr_adjusted_r2)"
      ],
      "metadata": {
        "id": "bCv6IlklvZYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_per_df.loc[0,'Model Name'] = 'Linear Regression'\n",
        "tuned_per_df.loc[0,'MAE'] = tuned_lr_mae\n",
        "tuned_per_df.loc[0,'MSE'] = tuned_lr_mse\n",
        "tuned_per_df.loc[0,'RMSE'] = tuned_lr_rmse\n",
        "tuned_per_df.loc[0,'R2'] = tuned_lr_r2\n",
        "tuned_per_df.loc[0,'ADJUSTED_R2'] = tuned_lr_adjusted_r2"
      ],
      "metadata": {
        "id": "I79TEO0Fwols"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason for using GridSearchCV is that it allows us to specify a range of hyperparameter values to be tested and automatically performs cross-validation to evaluate the model's performance for each combination of hyperparameters. This helps in finding the hyperparameters that yield the best performance on the validation data, thereby improving the generalization of the model to new, unseen data.\n",
        "\n",
        "GridSearchCV is a popular and widely used technique for hyperparameter tuning because it simplifies the process of finding the optimal hyperparameters while making sure the model is not overfitting the training data. By searching through a grid of hyperparameter values, GridSearchCV helps to identify the best hyperparameters that lead to better model performance."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, after using GridSearchCV for hyperparameter tuning, we observed improvements in the evaluation metric scores as follows:\n",
        "\n",
        "**Before Hyperparameter Tuning:**\n",
        "\n",
        "* Mean Absolute Error (mae): **4.81678**\n",
        "* Mean Squared Error (mse): **70.42041**\n",
        "* Root Mean Squared Error (rmse): **8.39169**\n",
        "* R-squared (r2): **0.99374**\n",
        "* Adjusted R-squared (adjusted_r2): **0.99317**\n",
        "\n",
        "**After Hyperparameter Tuning:**\n",
        "\n",
        "* Tuned Mean Absolute Error (tuned_lr_mae): **0.017328**\n",
        "* Tuned Mean Squared Error (tuned_lr_mse): **0.000814**\n",
        "* Tuned Root Mean Squared Error (tuned_lr_rmse): **0.02854**\n",
        "* Tuned R-squared (tuned_lr_r2): **0.99562**\n",
        "* Tuned Adjusted R-squared (tuned_lr_adjusted_r2): **0.99317**"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,4))\n",
        "# Evaluation metric names\n",
        "metrics = [ 'MAE', 'MSE', 'RMSE','R-squared', 'Adjusted R-squared']\n",
        "\n",
        "# Evaluation metric values\n",
        "values = [tuned_lr_mae, tuned_lr_mse, tuned_lr_rmse, tuned_lr_r2, tuned_lr_adjusted_r2]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.bar(metrics, values)"
      ],
      "metadata": {
        "id": "qD0DIP6A7BmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 **Lasso Regression**"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso"
      ],
      "metadata": {
        "id": "Xr4OMlFae56g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso(alpha = 0.1, max_iter = 3000)\n",
        "lasso.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "agwvL1BTe6Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.score(x_train, y_train)"
      ],
      "metadata": {
        "id": "_XQuFIgXe6Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lasso = lasso.predict(x_test)"
      ],
      "metadata": {
        "id": "mw4tYmIzwRzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.intercept_"
      ],
      "metadata": {
        "id": "i81ZWJaDftZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.coef_"
      ],
      "metadata": {
        "id": "CV8Fm1UOftd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance of metrics**"
      ],
      "metadata": {
        "id": "V5fm8amWyfCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = round(mean_absolute_error(10**(y_test), 10**(y_pred_lasso)),5)\n",
        "mse = round(mean_squared_error(10**(y_test), 10**(y_pred_lasso)),5)\n",
        "rmse = round(np.sqrt(mse),5)\n",
        "r2 = round(r2_score(10**(y_test), 10**(y_pred_lasso)),5)\n",
        "\n",
        "# Calculate the number of observations and the number of independent variables\n",
        "n = x_test.shape[0]\n",
        "k = x_test.shape[1]\n",
        "# Calculate the adjusted R-squared\n",
        "adjusted_r2 = round(1 - (1 - r2) * ((n - 1) / (n - k - 1)), 5)"
      ],
      "metadata": {
        "id": "q9w2Oh59fth1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MAE (Lasso) : {mae}\")\n",
        "print(f\"MSE (Lasso): {mse}\")\n",
        "print(f\"RMSE (Lasso): {rmse}\")\n",
        "print(f\"R-squared (Lasso): {r2}\")\n",
        "print(f\"Adjusted R-squared (Lasso): {adjusted_r2}\")"
      ],
      "metadata": {
        "id": "JtO6jEzct2qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inserting performance of metric tools in per_df\n",
        "per_df.loc[1,'Model Name'] = 'Lasso Regression'\n",
        "per_df.loc[1,'MAE'] = mae\n",
        "per_df.loc[1,'MSE'] = mse\n",
        "per_df.loc[1,'RMSE'] = rmse\n",
        "per_df.loc[1,'R2'] = r2\n",
        "per_df.loc[1,'ADJUSTED_R2'] = adjusted_r2"
      ],
      "metadata": {
        "id": "8Yr-eS2xuVm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,4))\n",
        "# Evaluation metric names\n",
        "metrics = [ 'MAE', 'MSE', 'RMSE','R-squared', 'Adjusted R-squared']\n",
        "\n",
        "# Evaluation metric values\n",
        "values = [mae, mse, rmse, r2, adjusted_r2]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.bar(metrics, values)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the actual and predicted test data.\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(10**y_pred_lasso)\n",
        "plt.plot(np.array(10**y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('Test Data')\n",
        "plt.ylabel(\"Price\")\n",
        "plt.title(\"Actual vs Predicted Closing price using Lasso regression\")"
      ],
      "metadata": {
        "id": "fGGd5I2ZyKud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the hyperparameter grid to search (empty for linear regression)\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,0.005,0.006,0.007,0.01,0.015,0.02,1e-1,1,5,10,20,30,40,45,50]}  # list of parameters.\n",
        "\n",
        "# Fit the model using GridSearchCV for hyperparameter tuning and cross-validation\n",
        "lasso_reg_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "lasso_reg_regressor.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_lasso = lasso_reg_regressor.predict(x_test)\n",
        "\n",
        "# Calculate evaluation metric values after cross validation and hyperparameter tuning\n",
        "tuned_lasso_mae = mean_absolute_error(y_test, y_pred_lasso)\n",
        "tuned_lasso_mse = mean_squared_error(y_test, y_pred_lasso)\n",
        "tuned_lasso_rmse = np.sqrt(tuned_lasso_mse)\n",
        "tuned_lasso_r2 = r2_score(y_test, y_pred_lasso)\n",
        "tuned_lasso_adjusted_r2 = round(1 - (1 - r2) * ((n - 1) / (n - k - 1)), 5)\n"
      ],
      "metadata": {
        "id": "nNiFS__tzN_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the evaluation metric values after cross validation and hyperparameter tuning\n",
        "print(\"Mean Absolute Error(Lasso):\", tuned_lasso_mae)\n",
        "print(\"Mean Squared Error(Lasso):\", tuned_lasso_mse)\n",
        "print(\"Root Mean Squared Error(Lasso):\", tuned_lasso_rmse)\n",
        "print(\"R-squared(Lasso):\", tuned_lasso_r2)\n",
        "print(\"Adjusted R-squared(Lasso):\", tuned_lasso_adjusted_r2)"
      ],
      "metadata": {
        "id": "p0QBvuSR0Thr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_per_df.loc[1,'Model Name'] = 'Lasso Regression'\n",
        "tuned_per_df.loc[1,'MAE'] = tuned_lasso_mae\n",
        "tuned_per_df.loc[1,'MSE'] = tuned_lasso_mse\n",
        "tuned_per_df.loc[1,'RMSE'] = tuned_lasso_rmse\n",
        "tuned_per_df.loc[1,'R2'] = tuned_lasso_r2\n",
        "tuned_per_df.loc[1,'ADJUSTED_R2'] = tuned_lasso_adjusted_r2"
      ],
      "metadata": {
        "id": "aj3akUV_0Tmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is used for hyperparameter optimization. It systematically searches through a predefined grid of hyperparameters and selects the best combination based on cross-validation performance. This helps to improve the model's predictive accuracy and achieve better evaluation metric scores."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, after using GridSearchCV for hyperparameter tuning, we observed improvements in the evaluation metric scores as follows:\n",
        "\n",
        "**Before Hyperparameter Tuning:**\n",
        "\n",
        "* Mean Absolute Error (mae): **32.746**\n",
        "* Mean Squared Error (mse): **2555.834**\n",
        "* Root Mean Squared Error (rmse): **50.555**\n",
        "* R-squared (r2): **0.7729**\n",
        "* Adjusted R-squared (adjusted_r2): **0.75229**\n",
        "\n",
        "**After Hyperparameter Tuning:**\n",
        "\n",
        "* Tuned Mean Absolute Error (tuned_lasso_mae): **0.0173**\n",
        "* Tuned Mean Squared Error (tuned_lasso_mse): **0.0008**\n",
        "* Tuned Root Mean Squared Error (tuned_lasso_rmse): **0.0285**\n",
        "* Tuned R-squared (tuned_lasso_r2): **0.9956**\n",
        "* Tuned Adjusted R-squared (tuned_lasso_adjusted_r2): **0.7522**"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,4))\n",
        "# Evaluation metric names\n",
        "metrics = [ 'MAE', 'MSE', 'RMSE','R-squared', 'Adjusted R-squared']\n",
        "\n",
        "# Evaluation metric values\n",
        "values = [tuned_lasso_mae, tuned_lasso_mse, tuned_lasso_rmse, tuned_lasso_r2, tuned_lasso_adjusted_r2]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.bar(metrics, values)"
      ],
      "metadata": {
        "id": "lu9Z1sOt06Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ML model's performance, as evaluated by these metrics, directly influences. A model with lower MAE, MSE, and RMSE and higher R-squared and Adjusted R-squared will lead to more accurate predictions, better decision-making, and improved operational efficiency."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 **Ridge Regression**"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge = Ridge(alpha=0.1)"
      ],
      "metadata": {
        "id": "bFtN5Veb5j5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "tvhthZiv5kBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.score(x_train, y_train)"
      ],
      "metadata": {
        "id": "iLFWYOT95kFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ridge = ridge.predict(x_test)"
      ],
      "metadata": {
        "id": "96mRhu716IDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance of metrics**"
      ],
      "metadata": {
        "id": "ip18lIqr66eE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = round(mean_absolute_error(10**(y_test), 10**(y_pred_ridge)),5)\n",
        "mse = round(mean_squared_error(10**(y_test), 10**(y_pred_ridge)),5)\n",
        "rmse = round(np.sqrt(mse),5)\n",
        "r2 = round(r2_score(10**(y_test), 10**(y_pred_ridge)),5)\n",
        "\n",
        "# Calculate the number of observations and the number of independent variables\n",
        "n = x_test.shape[0]\n",
        "k = x_test.shape[1]\n",
        "# Calculate the adjusted R-squared\n",
        "adjusted_r2 = round(1 - (1 - r2) * ((n - 1) / (n - k - 1)), 5)"
      ],
      "metadata": {
        "id": "mKxa5etS6IIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MAE (Ridge) : {mae}\")\n",
        "print(f\"MSE (Ridge): {mse}\")\n",
        "print(f\"RMSE (Ridge): {rmse}\")\n",
        "print(f\"R-squared (Ridge): {r2}\")\n",
        "print(f\"Adjusted R-squared (Ridge): {adjusted_r2}\")"
      ],
      "metadata": {
        "id": "fOJa6Ald6IM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inserting performance of metric tools in per_df\n",
        "per_df.loc[2,'Model Name'] = 'Ridge Regression'\n",
        "per_df.loc[2,'MAE'] = mae\n",
        "per_df.loc[2,'MSE'] = mse\n",
        "per_df.loc[2,'RMSE'] = rmse\n",
        "per_df.loc[2,'R2'] = r2\n",
        "per_df.loc[2,'ADJUSTED_R2'] = adjusted_r2"
      ],
      "metadata": {
        "id": "EsCQoZvP6IQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,4))\n",
        "# Evaluation metric names\n",
        "metrics = [ 'MAE', 'MSE', 'RMSE','R-squared', 'Adjusted R-squared']\n",
        "\n",
        "# Evaluation metric values\n",
        "values = [mae, mse, rmse, r2, adjusted_r2]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.bar(metrics, values)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the actual and predicted test data.\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(10**y_pred_ridge)\n",
        "plt.plot(np.array(10**y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('Test Data')\n",
        "plt.ylabel(\"Price\")\n",
        "plt.title(\"Actual vs Predicted Closing price using Lasso regression\")"
      ],
      "metadata": {
        "id": "DoDwiIVL6HCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the hyperparameter grid to search (empty for linear regression)\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,0.005,0.006,0.007,0.01,0.015,0.02,1e-1,1,5,10,20,30,40,45,50]}  # list of parameters.\n",
        "\n",
        "# Fit the model using GridSearchCV for hyperparameter tuning and cross-validation\n",
        "ridge_reg_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_reg_regressor.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_ridge = ridge_reg_regressor.predict(x_test)\n",
        "\n",
        "# Calculate evaluation metric values after cross validation and hyperparameter tuning\n",
        "tuned_ridge_mae = mean_absolute_error(y_test, y_pred_ridge)\n",
        "tuned_ridge_mse = mean_squared_error(y_test, y_pred_ridge)\n",
        "tuned_ridge_rmse = np.sqrt(tuned_ridge_mse)\n",
        "tuned_ridge_r2 = r2_score(y_test, y_pred_ridge)\n",
        "tuned_ridge_adjusted_r2 = round(1 - (1 - r2) * ((n - 1) / (n - k - 1)), 5)\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the evaluation metric values after cross validation and hyperparameter tuning\n",
        "print(\"Mean Absolute Error(Ridge):\", tuned_ridge_mae)\n",
        "print(\"Mean Squared Error(Ridge):\", tuned_ridge_mse)\n",
        "print(\"Root Mean Squared Error(Ridge):\", tuned_ridge_rmse)\n",
        "print(\"R-squared(Ridge):\", tuned_ridge_r2)\n",
        "print(\"Adjusted R-squared(Ridge):\", tuned_ridge_adjusted_r2)"
      ],
      "metadata": {
        "id": "LViw60Vb9ath"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_per_df.loc[2,'Model Name'] = 'Ridge Regression'\n",
        "tuned_per_df.loc[2,'MAE'] = tuned_ridge_mae\n",
        "tuned_per_df.loc[2,'MSE'] = tuned_ridge_mse\n",
        "tuned_per_df.loc[2,'RMSE'] = tuned_ridge_rmse\n",
        "tuned_per_df.loc[2,'R2'] = tuned_ridge_r2\n",
        "tuned_per_df.loc[2,'ADJUSTED_R2'] = tuned_lasso_adjusted_r2"
      ],
      "metadata": {
        "id": "UtP1X_CR9esQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, after using GridSearchCV for hyperparameter tuning, we observed improvements in the evaluation metric scores as follows:\n",
        "\n",
        "**Before Hyperparameter Tuning:**\n",
        "\n",
        "* Mean Absolute Error (mae): **4.96916**\n",
        "* Mean Squared Error (mse): **70.20436**\n",
        "* Root Mean Squared Error (rmse): **8.3788**\n",
        "* R-squared (r2): **0.99376**\n",
        "* Adjusted R-squared (adjusted_r2): **0.99319**\n",
        "\n",
        "**After Hyperparameter Tuning:**\n",
        "\n",
        "* Tuned Mean Absolute Error (tuned_ridge_mae): **0.01772075002**\n",
        "* Tuned Mean Squared Error (tuned_ridge_mse): **0.00086081638134**\n",
        "* Tuned Root Mean Squared Error (tuned_ridge_rmse): **0.029339672481907**\n",
        "* Tuned R-squared (tuned_ridge_r2): **0.995378969299**\n",
        "* Tuned Adjusted R-squared (tuned_ridge_adjusted_r2): **0.99319**"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,4))\n",
        "# Evaluation metric names\n",
        "metrics = [ 'MAE', 'MSE', 'RMSE','R-squared', 'Adjusted R-squared']\n",
        "\n",
        "# Evaluation metric values\n",
        "values = [tuned_ridge_mae, tuned_ridge_mse, tuned_ridge_rmse, tuned_ridge_r2, tuned_ridge_adjusted_r2]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.bar(metrics, values)"
      ],
      "metadata": {
        "id": "J2VRkYkuCLzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "MxtfAh95Cg1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ML model's performance, as evaluated by these metrics, directly influences. A model with lower MAE, MSE, and RMSE and higher R-squared and Adjusted R-squared will lead to more accurate predictions, better decision-making, and improved operational efficiency."
      ],
      "metadata": {
        "id": "cj6v0fT7Cg2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "per_df"
      ],
      "metadata": {
        "id": "JR9dwXjSB4AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_per_df"
      ],
      "metadata": {
        "id": "3s0rDoHhB6rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_per_df.plot(kind = 'bar')"
      ],
      "metadata": {
        "id": "ccT5aX4sD_Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "R-squared (r2) was chosen as an evaluation metric because it shows how well the model fits the data and explains the relationship between the input variables and the output. A higher R-squared means the model is better at predicting the target variable, which is essential for making reliable business decisions."
      ],
      "metadata": {
        "id": "7uKRt6TXLPj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final prediction model chosen was Linear Regression. Although all evaluation metrics (MAE, MSE, RMSE, and R-squared) were similar across the models, the deciding factor was the higher value of adjusted R-squared for Linear Regression. A higher adjusted R-squared indicates that Linear Regression is better at explaining the variance in the target variable while considering the number of predictors in the model. This suggests that Linear Regression provides a better fit for the data and is more reliable for making predictions in our specific scenario."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# save the model to a file\n",
        "joblib.dump(linear_reg_regressor, 'regression_model.joblib')\n",
        "\n",
        "# the First parameter is the name of the model and the second parameter is the name of the file\n",
        "# with which we want to save it\n",
        "\n",
        "# now the model named 'linear_reg_regressor' will be saved as 'regression_model.joblib' in the current directory."
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the joblib file\n",
        "loaded_model = joblib.load('regression_model.joblib')"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the unseen data\n",
        "predictions = loaded_model.predict(x_test)\n",
        "\n",
        "predictions_df = pd.DataFrame({'Predicted_Close_Price': predictions})\n",
        "# predictions_df.to_csv('predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "9ZwShXNQUxzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head(10)"
      ],
      "metadata": {
        "id": "-dAEJGj_VP8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "BF1ivaULVVXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we performed a comprehensive analysis of stock prices for Yes Bank. We started by understanding and exploring the dataset, which consisted of five columns representing the date, open, high, low, and close prices of the stock. We checked for missing values, duplicate entries, and identified the data types of each column.\n",
        "\n",
        "Next, we performed exploratory data analysis (EDA) to gain insights into the trends and patterns of the stock prices over time. We visualized the maximum and minimum stock prices for open and close prices, the difference between high and low prices over time, the variation of high and low prices over time, and the relationship between high and low prices. Additionally, we explored the difference between opening and closing prices and their relationship over time.\n",
        "\n",
        "After understanding the data, we conducted feature engineering and data pre-processing, which involved converting the date column to a datetime datatype, setting the date as the index, and applying log transforms on the independent and dependent variables. We split the data into training and testing sets and standardized the features.\n",
        "\n",
        "For modeling, we implemented three regression models - Linear Regression, Lasso Regression, and Ridge Regression. We evaluated each model's performance using various metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R-squared (R2), and Adjusted R-squared. We observed significant improvements in the model's performance after hyperparameter tuning using GridSearchCV.\n",
        "\n",
        "The best-performing model was determined based on the evaluation metrics, and Linear Regression was selected as the final prediction model. The Linear Regression model showed the highest Adjusted R-squared value, indicating a better fit and explaining more variance in the target variable.\n",
        "\n",
        "Finally, we saved the best-performing Linear Regression model as a joblib file for future deployment and prediction of unseen data.\n",
        "\n",
        "In conclusion, our analysis provided valuable insights into the stock prices of Yes Bank, and the selected Linear Regression model can be used for making predictions and assisting in investment decisions. Further improvements could be made by incorporating more features or trying different regression techniques to enhance the model's accuracy and performance."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}